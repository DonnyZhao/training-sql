{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Training: SQL (Heavy-users) ðŸ’ª\n",
                "Welcome to the training notebook on using SQL.\n",
                "\n",
                "\n",
                "This notebook is pitched at heavy users who perform data management rples to store objects permanently in SQL.\n",
                "\n",
                "![SQL Futurama meme](https://live.staticflickr.com/65535/49188193126_3b991de60e_z.jpg \"SQL Futurama meme\") \n",
                "\n",
                "# What will this session cover? ðŸ‘‚\n",
                "This session will show you how to do the following things in SQL:\n",
                "1. Dynmaic SQL querying\n",
                "1. Informal guide to when you should permanently store SQL objects\n",
                "1. Creating and updating tables\n",
                "1. Importing data into SQL\n",
                "1. Indexing columns to improve querying speeds\n",
                "1. Adding constraints to columns to restrict entries that can go inside it\n",
                "1. Using stored procedures and functions to do more bespoke operations\n",
                "1. Database triggers\n",
                "1. Version-controlling databases"
            ],
            "metadata": {
                "azdata_cell_guid": "a1525136-1fc3-4c51-85b0-ac160d7ff3ff"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- set database to use\r\n",
                "USE [HEFE-AN-DEV];"
            ],
            "metadata": {
                "azdata_cell_guid": "39a29ac5-eaa2-4825-87f9-a27728d31183",
                "tags": []
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 1. Dynamic SQL querying\r\n",
                "This is essentially SQL code that writes SQL code. It's particularly useful when you want to parameterise your SQL statements with an input variable. \r\n",
                "\r\n",
                "To be able to employ dynamic SQL querying, you'll need to know how to:\r\n",
                "1. Create a variable in SQL and assign it a value\r\n",
                "1. Create a SQL query which takes the variable you created\r\n",
                "1. Execute the SQL query\r\n",
                "\r\n",
                "The core idea behind dynamic SQL querying lies in being able to write your query as a string/varchar/text, and then execute/run the text as if it is a SQL query.\r\n",
                "\r\n",
                "> **USER STORY:** *As a lazy-ass, punk-ass, funk-ass SQL version of NAS, I want to quickly run a SQL statement to quickly count all the number of rows in several tables in my database rather than write the same* `SELECT COUNT(*) FROM <*table_name*>` *statement several times but with different table names, so I can get back to making my new coding mixtape.*\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "71db0edd-4215-4b60-b85e-590261e4b8f3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create and set variable/parameters\r\n",
                "DECLARE @name_schema AS NVARCHAR(25) = 'Production'\r\n",
                "DECLARE @name_table AS NVARCHAR(50) = 'Product'\r\n",
                "\r\n",
                "-- write dynamic SQL as string/text\r\n",
                "DECLARE @query AS NVARCHAR(MAX) = \r\n",
                "'\r\n",
                "    SELECT COUNT(*)\r\n",
                "    FROM [' + @name_schema + '].[' + @name_table + '];\r\n",
                "' \r\n",
                "\r\n",
                "-- print query to see what SQL is written\r\n",
                "PRINT @query\r\n",
                "\r\n",
                "-- excute dynamic SQL being written as string/text\r\n",
                "EXEC sp_executesql @query"
            ],
            "metadata": {
                "azdata_cell_guid": "fd3e44fa-e8d0-45ae-98cb-22cf1dbd922d"
            },
            "outputs": [],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "## EXERCISE: Dynamic SQL querying #1\r\n",
                "**Question:** Is there an even more efficient way to perform the same task in (1.) without having to use dynamic SQL querying?\r\n",
                "\r\n",
                "**Hint:** Consider using System Tables belonging to the `[INFORMATION_SCHEMA]`.\r\n",
                "\r\n",
                "**Note:** This exercise introduces you to some very useful tables that exist in the background which will be extremely useful for data management tasks. It also shows that dynamic SQL is not always the best option."
            ],
            "metadata": {
                "azdata_cell_guid": "5817afee-8c6d-49d0-b967-05dd245168f3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer here"
            ],
            "metadata": {
                "azdata_cell_guid": "85468e8e-cf2d-4313-bda4-65e96a148488"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## EXERCISE: Dynamic SQL querying #2\r\n",
                "**Question:** Recall in the *Training: SQL (Medium-user)* notebook the instructions for how you pivot tables in SQL. Namely, how you have to explicitly know and code the rows in the column you want to pivot to. This can be tedious, especially when you have many unique rows to pivot to. There is a way to pivot without explicitly specifying the rows you want to pivot to columns. Can you write a query that does this?\r\n",
                "\r\n",
                "**Note:** This exercise demonstrates the power of dynamic querying."
            ],
            "metadata": {
                "azdata_cell_guid": "6e90a391-50d2-4eeb-8b0b-479281a13cdd"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 2. Informal guide to what you should permanently store in SQL\r\n",
                "The attitude to storing data in SQL should be different to storing data in a folder. As a database administrator/architect/manager, your role is to effectively govern the storage and access of data so that it can be intuitively found, easily accessed and fluidly recycled/reused.\r\n",
                "\r\n",
                "This means that your data in SQL should meet the following criteria:\r\n",
                "- [ ] Be persistent - it should be able to hold different versions of your data across time series. *e.g. HESA return the 2015/16 data two times in the year, so both versions should go in a singled table with an column idenitifyin what version youre using.*\r\n",
                "- [ ] Folllow a style-guide - all naming must be consistent with each other so that users of the databse can navigatee easily to where they want to go.\r\n",
                "- [ ] Open access - enable a wide range of people to access your data.\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "3d1c9f51-2234-4b2d-b85b-9ca073c91df9"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 3. Creating and updating tables\r\n",
                "When deciding that **temporary tables** are unsuitable for your usage because you want to increase access to the data explicitly for more people or people will be building off your query to view the **CTE**, then creating and updating a table to store permanently in a SQL database is appropriate. \r\n",
                "\r\n",
                "When creating a table, you may want to store it in **tidy data format** (covered in *Training: SQL (Medium-users))*) so the same data but in a different version or time can be imported to this, meaning you are **updating** the ewly-created table.\r\n",
                "\r\n",
                "To create a table, you need to know a few things upfront such as the columns it will contain, their data types and version. \r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "892ceb54-a199-4f2c-94bd-4e403c49eb53"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "``` SQL\r\n",
                "-- template: create table query\r\n",
                "CREATE TABLE [<schema_name>].[<table_name>] (\r\n",
                "    [Column_1] AS <datatype>\r\n",
                "    ,[Column_2] AS <datatype>\r\n",
                "    ,...\r\n",
                ");\r\n",
                "\r\n",
                "-- template: update table \r\n",
                "UPDATE [<schema_name>].[<table_name>]\r\n",
                "SET [column_n] = <new_value>\r\n",
                "WHERE [column_j] = <filter_value>;\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "4ef853ab-8681-4308-bddf-29c10b60dd2e"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 4. Importing data into SQL\r\n",
                "After deciding that you want to store the data in a table on SQL, and having creatied the tables, you next job is to actually import the data into the table. There are several methods.\r\n",
                "1. **SQL Server Import Wizard:** Good for relatively quick, one-time imports of datasets. Bad for multiple table imports of the same datasets.\r\n",
                "1. `INSERT INTO [<schema_name>].[<table_name>] VALUES (row_1_value_1, row_1_value_2, ...), ...`: Good for realtively quick, one time imports of rows. Bad for anything outside of this.\r\n",
                "1. **SSIS Package:** Good for efficiently importing multiple tables of the same dataset. Bad for people not wanting to learn a new software.\r\n",
                "1. **R:** Good as most people know about how to do programme in this. Bad if you are trying to import a large amount of data.\r\n",
                "\r\n",
                "We define *large* in point (4.) with regards to the size of the ***data being imported into SQL being larger than the amount of RAM your computer has.*** This is because importing data into SQL from R requires importing the data into your R session first, then moving it across into SQL. As R stores data on the computers RAM for fast retrieval (relative to storage on a hard disk), then if the data was larger than the RAM, this would be a very slow process. "
            ],
            "metadata": {
                "azdata_cell_guid": "8175a594-dcdf-412c-976e-5b9f4f83015d"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 5. Indexing columns to improve querying speeds\r\n",
                "With really big tables, it makes sense to **index** their columns so that it is much more faster to query from them via filtering/joining or other SQL operations.\r\n",
                "\r\n",
                "**Column indexes/indices** are essentially a way of creating \"bookmarks\" in your data so that when you're filtering from it for instance, the SQL engine looks through the bookmarks and filters on them, rather than go into each entry, row-by-row, and filtering.\r\n",
                "\r\n",
                "They do slow down `UPDATE` and `INSERT` operations so you may want to drop **indexes** before performing these operations and then reapply the **indexes**.\r\n",
                "\r\n",
                "There are two types of **indexes**:\r\n",
                "- **Clustered:** Physically orders the data on the ~~hard~~ disk. This can make `ORDER BY` operations significantly faster.\r\n",
                "    + Only one can be created per table.\r\n",
                "    + Faster to read than non-clustered index as data is physically stored in an index order.\r\n",
                "    + Does not take additional memory to store.\r\n",
                "- **Non-clustered:** Defines a \"logical\" order that does not match the physical order on the ~~hard~~ disk. This \"logical\" order is like a layer on top of a physical order, where a pointer is used.\r\n",
                "    + More than one can be created per table as they can be applied to columns.\r\n",
                "    + Data insertion/update is faster than clustered index. \r\n",
                "    + Needs additional memory to store.\r\n",
                "\r\n",
                "![Clustered image](https://i.stack.imgur.com/kFSWR.png \"Clustered image\")\r\n",
                "\r\n",
                "> **TIP:** Typically, **clustered indexes** are created on the most unique column or columns in your data, such as a unique identifier (also known in SQL parlance as the **primary key**).\r\n",
                ">> For the most part, we use **non-clustered indexes** on columns which we plan to filter by and join on and drop them before inserting or updating data in the tables.\r\n",
                "\r\n",
                "```\r\n",
                "-- template: create index\r\n",
                "CREATE NONCLUSTERED INDEX IX_<table_name>_<column_name>\r\n",
                "    ON [<schema_name>].[<table_name>] ([<column_name>])\r\n",
                "    -- enable faster index creation/rebuild times\r\n",
                "    -- without this, can dramaticall increase tempdb file sizes, which is bad!\r\n",
                "    WITH (SORT_IN_TEMPDB = ON);\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "927c8c32-d60e-49c0-8c32-15d22c9e0293"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "```\r\n",
                "-- template: drop multiple indexes, checking if they exist first\r\n",
                "IF EXISTS \r\n",
                "(\r\n",
                "    SELECT [name] FROM [sys].[indexes]\r\n",
                "    WHERE [name] IN (N'IX_<table_name>_<column_name_1>', 'IX_<table_name>_<column_name_2>', ...)\r\n",
                ") \r\n",
                "BEGIN\r\n",
                "    DROP INDEX IX_<table_name>_<column_name_1>\r\n",
                "        ON [<schema_name>].[<table_name>]\r\n",
                "    DROP INDEX IX_<table_name>_<column_name_2>\r\n",
                "         ON [<schema_name>].[<table_name>]\r\n",
                "    ...\r\n",
                "END\r\n",
                "\r\n",
                "-- need to specify what to do if these indexes don't exist\r\n",
                "-- otherwise SSIS package will throw error because won't know\r\n",
                "-- what to do if indexes don't exist\r\n",
                "ELSE \r\n",
                "BEGIN\r\n",
                "    WAITFOR DELAY '00:00:00'\r\n",
                "END;\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "bb2b848d-b1b6-44ad-954e-569ba13695ab"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 6. Adding constraints to columns\r\n",
                "Adding **constraints** to columns in you data ensures the integrity of possible values being entered into the table. They specify rules that data must adhere to in your tables.\r\n",
                "\r\n",
                "Specifically of interest is the **check constraint** which sets a specified list of values that the column can take, and any data being entered into the table that does not fulfill this pre-specified list of values cannot be imported until this is resolved.\r\n",
                "\r\n",
                "```\r\n",
                "-- template: create constraint on existing table\r\n",
                "ALTER TABLE [<schema_name>].[<table_name>]\r\n",
                "ADD CONSTRAINT CHK_<constraint_name> CHECK ([<column_integer>] > n AND [<column_string>] IN ('string_1', 'string_2', ...))\r\n",
                "```\r\n",
                "\r\n",
                "```\r\n",
                "-- template: drop constrain on existing table\r\n",
                "ALTER TABLE [<schema_name>].[<table_name>]\r\n",
                "DROP CHECK CHK_<constraint_name>\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "a908338a-776e-4e2a-b27e-205f2972fbcf"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 7. Using stored procedures and functions\r\n",
                "**Stored procedures** and **functions** both execute a set of SQL instructions to return a result. Howeverm they are different in subtle ways.\r\n",
                "\r\n",
                "\r\n",
                "Stored Procedures | Functions\r\n",
                "--- | --- |\r\n",
                "Does not return a value, just `0` or `n` values | Always returns a value\r\n",
                "Can have input **and** output parameters | Only have input parameters for it\r\n",
                "Cannot call them from **Functions** | Can call them from **Stored Procedures**\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "1d9dbf7d-baf4-4088-842f-cf94c2e793ff"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create a simple stored proc\r\n",
                "CREATE PROCEDURE spr_HelloWorld\r\n",
                "AS\r\n",
                "PRINT 'Hello World'\r\n",
                "\r\n",
                "-- execute stored proc\r\n",
                "EXEC spr_HelloWorld"
            ],
            "metadata": {
                "azdata_cell_guid": "b6fdd391-990e-4629-8067-c214c11fa0eb",
                "tags": []
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "-- create a simple function\r\n",
                "CREATE FUNCTION dbo.fn_helloworld()\r\n",
                "RETURNS varchar(20)\r\n",
                "AS \r\n",
                "BEGIN\r\n",
                "\t RETURN 'Hello world'\r\n",
                "END;\r\n",
                "\r\n",
                "GO;\r\n",
                "\r\n",
                "-- call the function\r\n",
                "SELECT dbo.fn_helloworld()"
            ],
            "metadata": {
                "azdata_cell_guid": "322f0809-b16b-4523-a69d-f96fa40c09db"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 8. Database triggers to record activity"
            ],
            "metadata": {
                "azdata_cell_guid": "b7200740-bf37-44d0-8037-206f66c4291d"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create schema to assign database activity table in\r\n",
                "CREATE SCHEMA [AdminDetails] AUTHORIZATION [dbo];\r\n",
                "GO;\r\n",
                "\r\n",
                "-- create table to record database activity\r\n",
                "CREATE TABLE [AuditDetails].[DatabaseChangeLog](\r\n",
                "\t[ChangeId] [int] IDENTITY(1,1) NOT NULL\r\n",
                "\t,[ChangeDate] [datetime] NOT NULL \r\n",
                "\t\tCONSTRAINT [DF_ddl_log_ChangeDate]\r\n",
                "\t\t\tDEFAULT (GETDATE())\r\n",
                "\t,[NameUser] [nvarchar](50) NOT NULL\r\n",
                "\t\tCONSTRAINT [DF_ddl_log_NameUser]   \r\n",
                "            DEFAULT (CONVERT([nvarchar](50), USER_NAME(), (0)))\r\n",
                "\t,[NameSecurity] [nvarchar](50) NOT NULL\r\n",
                "\t\tCONSTRAINT [DF_DDLChangeLog_NameSecurity]   \r\n",
                "            DEFAULT (CONVERT([nvarchar](50), SUSER_SNAME(), (0)))\r\n",
                "\t,[NameLogin] [nvarchar](50) NOT NULL\r\n",
                "\t\tCONSTRAINT [DF_DDLChangeLog_NameLogin]   \r\n",
                "            DEFAULT (CONVERT([nvarchar](50), original_login(),(0)))\r\n",
                "\t,[EventType] [nvarchar](100) NULL\r\n",
                "\t,[ObjectName] [nvarchar](100) NULL\r\n",
                "\t,[ObjectType] [nvarchar](100) NULL\r\n",
                "\t,[TsqlCode] [nvarchar](max) NULL\r\n",
                ") ON [PRIMARY] TEXTIMAGE_ON [PRIMARY];\r\n",
                "GO;\r\n",
                "\r\n",
                "-- create and turn on database trigger\r\n",
                "CREATE TRIGGER trg_DatabaseChangeLog ON DATABASE \r\n",
                "    FOR DDL_DATABASE_LEVEL_EVENTS \r\n",
                "AS \r\n",
                "    DECLARE @data XML \r\n",
                "    SET @data = EVENTDATA() \r\n",
                "    IF @data.value('(/EVENT_INSTANCE/EventType)[1]', 'nvarchar(100)') <> 'CREATE_STATISTICS'  \r\n",
                "\t\tINSERT  INTO [DatabaseChangeLog] \r\n",
                "\t\t( \r\n",
                "\t\t\t[EventType], \r\n",
                "\t\t\t[ObjectName], \r\n",
                "\t\t\t[ObjectType], \r\n",
                "\t\t\t[TsqlCode]\r\n",
                "\t\t) \r\n",
                "\t\tVALUES  \r\n",
                "\t\t( \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/EventType)[1]', 'nvarchar(100)'), \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/ObjectName)[1]', 'nvarchar(100)'), \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/ObjectType)[1]', 'nvarchar(100)'), \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/TSQLCommand)[1]', 'nvarchar(max)') \r\n",
                "\t\t); \r\n",
                "GO\r\n",
                "\r\n",
                "ENABLE TRIGGER [trg_DatabaseChangeLog] ON DATABASE;\r\n",
                "GO;\r\n",
                "\r\n",
                "-- create View to pull in schema name so can better identify tables\r\n",
                "CREATE VIEW [AuditDetails].[vw_DatabaseChangeLog]\r\n",
                "AS \r\n",
                "(\r\n",
                "    SELECT changelog.[ChangeId]\r\n",
                "        ,changelog.[ChangeDate]\r\n",
                "        ,changelog.[NameUser]\r\n",
                "        ,changelog.[NameSecurity]\r\n",
                "        ,changelog.[NameLogin]\r\n",
                "        ,changelog.[EventType]\r\n",
                "        ,[SchemaId] = admintable.[schema_id]\r\n",
                "        ,[SchemaName] = OBJECT_SCHEMA_NAME(admintable.[object_id])\r\n",
                "        ,[ObjectId] = admintable.[object_id]\r\n",
                "        ,changelog.[ObjectName]\r\n",
                "        ,[ObjectType] = admintable.[type_desc]\r\n",
                "        ,changelog.[TsqlCode]\r\n",
                "    FROM [AuditDetails].[DatabaseChangeLog] AS changelog\r\n",
                "    LEFT JOIN [sys].[all_objects] AS admintable\r\n",
                "        ON changelog.[objectName] = admintable.[name]\r\n",
                "    -- Keep only 'genuine'/real-people SQL users\r\n",
                "    WHERE changelog.[NameUser] != 'dbo'\r\n",
                ")"
            ],
            "metadata": {
                "azdata_cell_guid": "18c2a9d5-b078-40d0-bd3e-01a4278f2913"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 9. Version-controlling your database\r\n",
                "\r\n",
                "Additional guidance is available on Github [here](https://github.com/avisionh/SQL-Titbits/wiki/User-Guide:-SQL-x-Git-Version-Control)."
            ],
            "metadata": {
                "azdata_cell_guid": "1137155a-2062-499a-acc0-2f5fcb94c1f9"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ed2e5d34-5e33-490f-abe7-c1df48ebd7bf"
            }
        }
    ]
}